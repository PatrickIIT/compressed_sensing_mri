{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":8664238,"sourceType":"datasetVersion","datasetId":5191625}],"dockerImageVersionId":31040,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install numpy torch scikit-image h5py pywt matplotlib","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import os\nimport glob\nimport h5py\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom skimage.metrics import peak_signal_noise_ratio as psnr\nfrom skimage.metrics import structural_similarity as ssim\nimport matplotlib.pyplot as plt\nimport pywt\nfrom numpy.fft import fft2, ifft2, fftshift, ifftshift\nfrom skimage.transform import resize\nimport time\nimport gc\n\n# Set random seed for reproducibility\nnp.random.seed(42)\ntorch.manual_seed(42)\n\n# Device configuration\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nprint(f\"Using device: {device}\")\n\n# --- Mini U-Net CNN Architecture ---\nclass MiniUNet(nn.Module):\n    def __init__(self, img_size=256):\n        super(MiniUNet, self).__init__()\n        # Encoder\n        self.enc1 = nn.Conv2d(2, 32, 3, padding=1)  # Input: real+imag\n        self.enc2 = nn.Conv2d(32, 64, 3, padding=1)\n        # Bottleneck\n        self.bottleneck = nn.Conv2d(64, 128, 3, padding=1)\n        # Decoder\n        self.dec2 = nn.Conv2d(192, 64, 3, padding=1)  # Skip connection\n        self.dec1 = nn.Conv2d(96, 32, 3, padding=1)\n        self.out = nn.Conv2d(32, 1, 3, padding=1)  # Output: real image\n        self.relu = nn.ReLU()\n        self.pool = nn.MaxPool2d(2)\n        self.upsample = nn.Upsample(scale_factor=2, mode='bilinear', align_corners=True)\n\n    def forward(self, x):\n        # Encoder\n        e1 = self.relu(self.enc1(x))  # [B, 32, img_size, img_size]\n        e2 = self.relu(self.enc2(self.pool(e1)))  # [B, 64, img_size/2, img_size/2]\n        # Bottleneck\n        b = self.relu(self.bottleneck(self.pool(e2)))  # [B, 128, img_size/4, img_size/4]\n        # Decoder with skip connections\n        d2 = self.relu(self.dec2(torch.cat([self.upsample(b), e2], dim=1)))  # [B, 64, img_size/2]\n        d1 = self.relu(self.dec1(torch.cat([self.upsample(d2), e1], dim=1)))  # [B, 32, img_size]\n        out = self.out(d1)  # [B, 1, img_size, img_size]\n        return out\n\n# --- Dataset Loading ---\ndef load_fastmri_slices(base_path, num_subjects=10, slices_per_subject=5):\n    h5_files = glob.glob(os.path.join(base_path, '*.h5'))\n    if not h5_files:\n        print(f\"ERROR: No .h5 files found in {base_path}\")\n        return [], []\n\n    num_subjects = min(num_subjects, len(h5_files))\n    h5_files = h5_files[:num_subjects]\n    images = []\n    subjects_slices = []\n\n    for h5_path in h5_files:\n        try:\n            with h5py.File(h5_path, 'r') as f:\n                kspace = f['kspace'][()]  # Shape: (slices, coils, height, width)\n                num_slices = kspace.shape[0]\n                central_idx = num_slices // 2\n                slice_indices = range(central_idx - slices_per_subject//2, central_idx + slices_per_subject//2 + 1)\n                subject_id = os.path.basename(h5_path).split('.')[0]\n\n                for slice_idx in slice_indices:\n                    if slice_idx < 0 or slice_idx >= num_slices:\n                        continue\n                    kspace_slice = kspace[slice_idx]  # Shape: (coils, height, width)\n                    img_coils = ifft2(ifftshift(kspace_slice, axes=(1, 2)), axes=(1, 2))\n                    img_rss = np.sqrt(np.sum(np.abs(img_coils)**2, axis=0))\n                    img_rss = resize(img_rss, (256, 256), anti_aliasing=True).astype(np.float32)\n                    if np.max(img_rss) > np.min(img_rss):\n                        img_rss = (img_rss - np.min(img_rss)) / (np.max(img_rss) - np.min(img_rss))\n                    else:\n                        img_rss = np.zeros_like(img_rss)\n                    images.append(img_rss)\n                    subjects_slices.append((subject_id, slice_idx))\n        except Exception as e:\n            print(f\"ERROR loading {h5_path}: {e}\")\n            continue\n\n    return np.array(images), subjects_slices\n\n# --- Mask and Reconstruction Functions ---\ndef create_variable_density_mask(shape, acceleration_factor, center_fraction=0.08, poly_degree=2, seed=None):\n    if seed is not None:\n        np.random.seed(seed)\n    rows, cols = shape\n    center_x, center_y = cols // 2, rows // 2\n    x_coords = np.abs(np.arange(cols) - center_x)\n    y_coords = np.abs(np.arange(rows) - center_y)\n    dist_x, dist_y = np.meshgrid(x_coords, y_coords)\n    norm_dist_x = dist_x / (np.max(dist_x) if np.max(dist_x) > 0 else 1)\n    norm_dist_y = dist_y / (np.max(dist_y) if np.max(dist_y) > 0 else 1)\n    pdf = (1 - norm_dist_x**poly_degree) * (1 - norm_dist_y**poly_degree)\n    pdf = np.clip(pdf, 0, 1)\n    target_samples = int(np.prod(shape) / acceleration_factor)\n    flat_pdf = pdf.flatten()\n    sorted_indices = np.argsort(-flat_pdf)\n    mask = np.zeros(shape, dtype=bool).flatten()\n    mask[sorted_indices[:target_samples]] = True\n    mask = mask.reshape(shape)\n    center_rows_abs = int(shape[0] * center_fraction)\n    center_cols_abs = int(shape[1] * center_fraction)\n    r_start, r_end = shape[0]//2 - center_rows_abs//2, shape[0]//2 + center_rows_abs//2\n    c_start, c_end = shape[1]//2 - center_cols_abs//2, shape[1]//2 + center_cols_abs//2\n    mask[r_start:r_end, c_start:c_end] = True\n    actual_accel = np.prod(shape) / np.sum(mask)\n    print(f\"Variable Density Mask: Target R={acceleration_factor}, Actual R={actual_accel:.2f}\")\n    return mask.astype(np.float32)\n\ndef apply_mask(img, mask):\n    kspace = fftshift(fft2(img))\n    undersampled_kspace = kspace * mask\n    return undersampled_kspace, kspace\n\ndef zero_filled_reconstruction(undersampled_kspace):\n    img_zf = np.abs(ifft2(ifftshift(undersampled_kspace)))\n    return np.clip(img_zf, 0, 1)\n\ndef prepare_cnn_input(undersampled_kspace):\n    zf_img = ifft2(ifftshift(undersampled_kspace))\n    zf_real = np.real(zf_img)\n    zf_imag = np.imag(zf_img)\n    input_tensor = np.stack([zf_real, zf_imag], axis=0)  # [2, 256, 256]\n    return torch.tensor(input_tensor, dtype=torch.float32).unsqueeze(0)  # [1, 2, 256, 256]\n\n# --- ISTA Functions (from provided script) ---\ndef soft_threshold(x, threshold):\n    return np.sign(x) * np.maximum(np.abs(x) - threshold, 0)\n\ndef wavelet_forward(image, wavelet='db4', level=3):\n    coeffs = pywt.wavedec2(image, wavelet=wavelet, level=level)\n    arr, coeff_slices = pywt.coeffs_to_array(coeffs)\n    return arr, coeff_slices\n\ndef wavelet_inverse(arr, coeff_slices, wavelet='db4'):\n    coeffs_from_arr = pywt.array_to_coeffs(arr, coeff_slices, output_format='wavedec2')\n    return pywt.waverec2(coeffs_from_arr, wavelet=wavelet)\n\ndef ista_wavelet_cs(k_space_undersampled, mask, initial_image, n_iters, lambda_val, ground_truth_for_psnr):\n    x_recon = initial_image.copy().astype(np.complex128)\n    k_space_undersampled = k_space_undersampled.astype(np.complex128)\n    step_size = 1.0\n    for i in range(n_iters):\n        current_k_space = fftshift(fft2(x_recon))\n        k_space_error = (current_k_space * mask) - k_space_undersampled\n        grad_data_term = ifft2(ifftshift(k_space_error * mask))\n        x_intermediate = x_recon - step_size * grad_data_term\n        x_intermediate_real = np.real(x_intermediate)\n        coeffs_arr, coeff_slices = wavelet_forward(x_intermediate_real, wavelet='db4', level=3)\n        threshold = lambda_val * step_size\n        coeffs_list_form = pywt.wavedec2(x_intermediate_real, wavelet='db4', level=3)\n        approx_coeffs_size = coeffs_list_form[0].size\n        coeffs_arr_thresh = coeffs_arr.copy()\n        coeffs_arr_thresh[approx_coeffs_size:] = soft_threshold(coeffs_arr[approx_coeffs_size:], threshold)\n        x_reconstructed_real = wavelet_inverse(coeffs_arr_thresh, coeff_slices, wavelet='db4')\n        x_recon = x_reconstructed_real.astype(np.complex128)\n    return np.clip(np.real(x_recon), 0, 1)\n\n# --- Dataset Class ---\nclass FastMRIDataset(torch.utils.data.Dataset):\n    def __init__(self, images, mask):\n        self.images = images  # [num_images, 256, 256]\n        self.mask = mask  # [256, 256]\n    \n    def __len__(self):\n        return len(self.images)\n    \n    def __getitem__(self, idx):\n        img = self.images[idx]\n        undersampled_kspace, _ = apply_mask(img, self.mask)\n        input_tensor = prepare_cnn_input(undersampled_kspace)\n        target = torch.tensor(img[None], dtype=torch.float32)  # [1, 256, 256]\n        return input_tensor.squeeze(0), target  # [2, 256, 256], [1, 256, 256]\n\n# --- Training Function ---\ndef train_cnn(model, dataset, epochs=50, batch_size=4, lr=0.001):\n    model = model.to(device)\n    criterion = nn.MSELoss()\n    optimizer = optim.Adam(model.parameters(), lr=lr)\n    dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)\n    \n    for epoch in range(epochs):\n        model.train()\n        total_loss = 0\n        for inputs, targets in dataloader:\n            inputs, targets = inputs.to(device), targets.to(device)  # [B, 2, 256, 256], [B, 1, 256, 256]\n            optimizer.zero_grad()\n            outputs = model(inputs)  # [B, 1, 256, 256]\n            loss = criterion(outputs, targets)\n            loss.backward()\n            optimizer.step()\n            total_loss += loss.item()\n        if epoch % 10 == 0:\n            print(f'Epoch {epoch}, Loss: {total_loss / len(dataloader):.4f}')\n    return model\n\n# --- Evaluation Function ---\ndef evaluate_reconstruction(img_recon, img_ref):\n    img_recon = np.clip(img_recon, 0, 1)\n    img_ref = np.clip(img_ref, 0, 1)\n    psnr_val = psnr(img_ref, img_recon, data_range=1.0)\n    ssim_val = ssim(img_ref, img_recon, data_range=1.0, channel_axis=None)\n    return psnr_val, ssim_val\n\n# --- Main Function ---\ndef main():\n    # Define parameters\n    base_path = '/kaggle/input/fastmri-brain-multicoil'  # Replace with local path if not on Kaggle\n    acceleration_factor = 4\n    optimal_lambda = 0.0001\n    optimal_iters = 10\n\n    # Load dataset\n    images, subjects_slices = load_fastmri_slices(base_path, num_subjects=10, slices_per_subject=5)\n    if len(images) == 0:\n        raise RuntimeError(\"No valid images loaded. Check dataset path.\")\n\n    # Create mask\n    mask = create_variable_density_mask((256, 256), acceleration_factor, seed=0)\n\n    # Split dataset (8 subjects for training, 2 for testing)\n    train_images = images[:40]  # 8 subjects * 5 slices\n    test_images = images[40:]   # 2 subjects * 5 slices\n    test_subjects_slices = subjects_slices[40:]\n\n    # Create training dataset\n    train_dataset = FastMRIDataset(train_images, mask)\n\n    # Initialize and train CNN\n    model = MiniUNet(img_size=256)\n    start_time = time.time()\n    trained_model = train_cnn(model, train_dataset, epochs=50, batch_size=4)\n    cnn_train_time = time.time() - start_time\n\n    # Evaluate on test slices\n    results = {'ZF': [], 'ISTA': [], 'CNN': []}\n    for idx, (test_img, (subject_id, slice_idx)) in enumerate(zip(test_images, test_subjects_slices)):\n        print(f'\\nEvaluating {subject_id}, Slice {slice_idx}')\n        undersampled_kspace, _ = apply_mask(test_img, mask)\n\n        # Zero-Filled\n        start_time = time.time()\n        img_zf = zero_filled_reconstruction(undersampled_kspace)\n        zf_time = time.time() - start_time\n        zf_psnr, zf_ssim = evaluate_reconstruction(img_zf, test_img)\n        results['ZF'].append((zf_psnr, zf_ssim, zf_time))\n        print(f'Zero-Filled: PSNR={zf_psnr:.3f}, SSIM={zf_ssim:.4f}, Time={zf_time:.2f}s')\n\n        # ISTA\n        start_time = time.time()\n        img_ista = ista_wavelet_cs(undersampled_kspace, mask, img_zf.copy(), optimal_iters, optimal_lambda, test_img)\n        ista_time = time.time() - start_time\n        ista_psnr, ista_ssim = evaluate_reconstruction(img_ista, test_img)\n        results['ISTA'].append((ista_psnr, ista_ssim, ista_time))\n        print(f'ISTA: PSNR={ista_psnr:.3f}, SSIM={ista_ssim:.4f}, Time={ista_time:.2f}s')\n\n        # CNN\n        start_time = time.time()\n        input_tensor = prepare_cnn_input(undersampled_kspace)\n        with torch.no_grad():\n            output = trained_model(input_tensor.to(device))\n            img_cnn = output.squeeze().cpu().numpy()  # [256, 256]\n        cnn_inf_time = time.time() - start_time\n        cnn_psnr, cnn_ssim = evaluate_reconstruction(img_cnn, test_img)\n        results['CNN'].append((cnn_psnr, cnn_ssim, cnn_inf_time))\n        print(f'CNN: PSNR={cnn_psnr:.3f}, SSIM={cnn_ssim:.4f}, Inference Time={cnn_inf_time:.2f}s')\n\n        # Visualize\n        plt.figure(figsize=(12, 4))\n        plt.subplot(1, 4, 1)\n        plt.imshow(test_img, cmap='gray')\n        plt.title('Ground Truth')\n        plt.axis('off')\n        plt.subplot(1, 4, 2)\n        plt.imshow(img_zf, cmap='gray')\n        plt.title(f'ZF\\nPSNR: {zf_psnr:.2f}\\nSSIM: {zf_ssim:.4f}')\n        plt.axis('off')\n        plt.subplot(1, 4, 3)\n        plt.imshow(img_ista, cmap='gray')\n        plt.title(f'ISTA\\nPSNR: {ista_psnr:.2f}\\nSSIM: {ista_ssim:.4f}')\n        plt.axis('off')\n        plt.subplot(1, 4, 4)\n        plt.imshow(img_cnn, cmap='gray')\n        plt.title(f'CNN\\nPSNR: {cnn_psnr:.2f}\\nSSIM: {cnn_ssim:.4f}')\n        plt.axis('off')\n        plt.tight_layout()\n        plt.savefig(f'result_{subject_id}_slice_{slice_idx}.png', dpi=300)\n        plt.close()\n        gc.collect()\n\n    # Summarize results\n    print(\"\\n--- Summary of Results (R=4) ---\")\n    print(f\"{'Method':<10} | {'Mean PSNR':<12} | {'Mean SSIM':<12} | {'Mean Time (s)':<15}\")\n    print(\"-\" * 50)\n    for method in results:\n        psnr_vals, ssim_vals, times = zip(*results[method])\n        mean_psnr = np.mean(psnr_vals)\n        mean_ssim = np.mean(ssim_vals)\n        mean_time = np.mean(times)\n        print(f\"{method:<10} | {mean_psnr:.2f} | {mean_ssim:.4f} | {mean_time:.2f}\")\n    print(f'\\nCNN Total Time (Train+Inf): ~{cnn_train_time + np.mean([r[2] for r in results[\"CNN\"]]):.2f}s')\n\nif __name__ == '__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-23T06:19:33.015137Z","iopub.execute_input":"2025-06-23T06:19:33.015586Z","iopub.status.idle":"2025-06-23T06:37:39.526594Z","shell.execute_reply.started":"2025-06-23T06:19:33.015541Z","shell.execute_reply":"2025-06-23T06:37:39.525616Z"}},"outputs":[{"name":"stdout","text":"Using device: cpu\nERROR loading /kaggle/input/fastmri-brain-multicoil/file_brain_AXT2_210_2100179.h5: Unable to synchronously open file (truncated file: eof = 201064448, sblock->base_addr = 0, stored_eof = 778585656)\nVariable Density Mask: Target R=4, Actual R=4.00\nEpoch 0, Loss: 0.0131\nEpoch 10, Loss: 0.0001\nEpoch 20, Loss: 0.0001\nEpoch 30, Loss: 0.0000\nEpoch 40, Loss: 0.0000\n\nEvaluating file_brain_AXT2_207_2070286, Slice 6\nZero-Filled: PSNR=44.318, SSIM=0.9899, Time=0.00s\nISTA: PSNR=44.327, SSIM=0.9899, Time=0.13s\nCNN: PSNR=43.906, SSIM=0.9892, Inference Time=0.18s\n\nEvaluating file_brain_AXT2_207_2070286, Slice 7\nZero-Filled: PSNR=44.738, SSIM=0.9910, Time=0.00s\nISTA: PSNR=44.740, SSIM=0.9910, Time=0.10s\nCNN: PSNR=44.214, SSIM=0.9902, Inference Time=0.12s\n\nEvaluating file_brain_AXT2_207_2070286, Slice 8\nZero-Filled: PSNR=45.511, SSIM=0.9927, Time=0.00s\nISTA: PSNR=45.511, SSIM=0.9927, Time=0.11s\nCNN: PSNR=44.931, SSIM=0.9916, Inference Time=0.13s\n\nEvaluating file_brain_AXT2_207_2070286, Slice 9\nZero-Filled: PSNR=43.519, SSIM=0.9913, Time=0.00s\nISTA: PSNR=43.519, SSIM=0.9913, Time=0.11s\nCNN: PSNR=43.489, SSIM=0.9905, Inference Time=0.12s\n\nEvaluating file_brain_AXT2_207_2070286, Slice 10\nZero-Filled: PSNR=42.800, SSIM=0.9920, Time=0.00s\nISTA: PSNR=42.801, SSIM=0.9920, Time=0.11s\nCNN: PSNR=43.033, SSIM=0.9913, Inference Time=0.12s\n\n--- Summary of Results (R=4) ---\nMethod     | Mean PSNR    | Mean SSIM    | Mean Time (s)  \n--------------------------------------------------\nZF         | 44.18 | 0.9914 | 0.00\nISTA       | 44.18 | 0.9914 | 0.11\nCNN        | 43.91 | 0.9906 | 0.14\n\nCNN Total Time (Train+Inf): ~1056.34s\n","output_type":"stream"}],"execution_count":1}]}